FROM ghcr.io/ggerganov/llama.cpp:server--b1-9635529

RUN apt-get update
RUN apt-get install -y curl

RUN mkdir -p /models && \
    chmod -R 777 /models

# RUN curl -L https://huggingface.co/GPT4All-Community/Meta-Llama-3.1-8B-Instruct-128k-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-128k-f16.gguf --output /models/Meta-Llama-3.1-8B-Instruct-128k-f16.gguf

ENTRYPOINT /server --model /models/gpt4all-falcon-newbpe-q4_0.gguf \
        -c 512 \
        --host 0.0.0.0 \
        --port 8080 \
        --ctx-size 2048 \
        --parallel 1 \
        --n-predict 2048